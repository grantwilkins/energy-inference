/home/ac.gwilkins/.conda/envs/fedsz2/lib/python3.11/site-packages/transformers/utils/hub.py:122: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Downloading shards:   0%|          | 0/19 [00:00<?, ?it/s]Downloading shards: 100%|██████████| 19/19 [00:00<00:00, 1364.19it/s]
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:11<03:18, 11.01s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:24<03:27, 12.19s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:36<03:18, 12.42s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:48<03:03, 12.25s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [01:01<02:54, 12.47s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [01:14<02:44, 12.62s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [01:22<02:14, 11.23s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [01:26<01:37,  8.90s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [01:30<01:13,  7.38s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [01:34<00:57,  6.36s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [01:38<00:45,  5.63s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [01:46<00:42,  6.13s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [01:55<00:42,  7.11s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [02:03<00:37,  7.47s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [02:12<00:31,  7.91s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [02:21<00:24,  8.12s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [02:21<00:04,  4.40s/it]Loading checkpoint shards: 100%|██████████| 19/19 [02:21<00:00,  7.45s/it]
WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
slurmstepd: error: *** JOB 87331 ON gpu6 CANCELLED AT 2024-01-25T20:58:53 DUE TO TIME LIMIT ***
